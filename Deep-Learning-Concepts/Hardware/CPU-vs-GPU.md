-   **CPU**: A CPU has a small number of cores (often 4 to 16 in consumer devices, more in high-performance systems), each capable of handling multiple threads using techniques like **hyper-threading**. CPUs are optimized for sequential tasks and complex operations, where each core handles a few threads with high individual performance. They can do parallel work but are primarily designed for versatility and handling different types of tasks efficiently.
    
-   **GPU**: A GPU, on the other hand, has **thousands** of smaller, simpler cores designed for massive parallelism. GPUs excel at handling many threads simultaneously, making them ideal for tasks where a large number of simple operations need to be performed in parallel, such as processing large datasets or running machine learning models.
