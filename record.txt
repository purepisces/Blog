<img src="mean_std.png" alt="mean_std" width="400" height="300"/>
> Note: The output layer's neuron count often differs from the input layer. Each layer can have a distinct number of neurons, indicating its 'size' or capacity.
>
## Reference:
- [Watch the video on YouTube](https://youtube.com/watch?v=jTzJ9zjC8nU)
$\text{SSR}(a, b) = \sum\limits_{i=1}^{n} (y_i - ax_i - b)^2$
matrix:
$$
\begin{pmatrix}

0.8944272 & 0.4472136\\
-0.4472136 & -0.8944272
\end{pmatrix}
\begin{pmatrix}
10 & 0\\ 
0 & 5
\end{pmatrix}
$$

Editor: https://stackedit.io/app#

1.ffnn.md✅已发csdn+知乎
2.linear-regression.md✅已发csdn
3.variance&standarDeviation.md✅
4.Covariance.md ❌ need further improvement for pca
5.Linearity.md❌ need further improvement for why the product of the standard deviations of x and y is normalization? Which is correlated to correlation.
6.p_values.md✅
7.Correlation.md✅
8.r-squared.md✅ 已发csdn
9.statistical-significance.md✅
10.Standard-Deviation-vs-Standard-Error.md✅
11.Confidence-Intervals.md✅
12.least-squared.md✅
13.calculus.md✅
14.gradient-descent.md✅ need further math formula format improvement, need format and refrase
15.Neural-Network.md✅
16.backpropagation.md✅ need format and rephrase
17.relu.md✅ need format and rephrase
18.activation-functions.md✅ 已发csdn+知乎 need format and rephrase, Comparison with different activation Functions, why and when choose which
19.sigmoid.md✅已发csdn+知乎
20.tanh.md✅
21.neural-network-models.md✅
22.Linear-Layer.md✅ need further modification
23.softmax.md✅已发csdn,未发知乎
24.Cross_Entropy_Loss.md✅已发csdn,未发知乎 why dldlogits not dldsoftmax???
25.MSE_Loss.md✅已发csdn,未发知乎
26.Loss_Functions.md✅已发csdn,未发知乎
27.sgd.md✅已发csdn,未发知乎
28.one-hot-encoding.md✅
29.original_transformer.md 加一下代码部分更完善 encoder only decoder only and encoder-decoder可以概括的更详细一些 alson include interview questions about transformer
30.handling-imbalance.md✅ need further formatting 已发csdn,未发知乎
31.precision-recall-f1score.md✅已发csdn,未发知乎
32.video_recommendation.md✅已发csdn,未发知乎
33.feed_ranking.md✅已发csdn,未发知乎, 很多都用的ml system design课程内容的言论
34.underfitting-overfitting.md✅已发csdn
35.decision-tree.md✅ add regression tree explanation in statquest youtube under it
36.logistic-regression.md✅已发csdn
37.confusion-matrix.md✅已发csdn
38.softmax-regression.md✅已发csdn
39.knn-overview.md✅ 可以加一下https://cs231n.github.io/assignments2024/assignment1/的代码




PCA
SGD
bayer's theorem
naive bayes
Bayesian Network
**Cosine** and **Pearson Correlation** are techniques used to find resemblance in recommendation systems. 
cross-validation
Bayesian Network
XGBoost
SVM 
time series
Gradient Boosting
standard error
random forest
maximum likelihood
pruning 
cross validation
expected value
exponential function
decision tree (gradient boost decision tree)
regualization
L1 Regularization
L2 Regularization
boosting
bagging
auc and roc curve
precision-recall-f1score.md
Chain rule
K-Means Clustering
KNN
Cumulative Distribution Function (CDF)
Standard Gaussian Distributio
gelu
t-sne
implicit function
scalar function
Directional Derivative:
Gaussian Noise
probability mass function (PMF) and a probability density function (PDF)
Wald's test


why gradient" refers to a vector that points in the direction of the greatest rate of increase  give specific example???
why the product of the standard deviations of x and y is normalization?
